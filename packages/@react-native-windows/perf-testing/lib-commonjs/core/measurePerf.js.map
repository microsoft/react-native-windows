{"version":3,"file":"measurePerf.js","sourceRoot":"","sources":["../../src/core/measurePerf.ts"],"names":[],"mappings":";AAAA;;;;;GAKG;;;;;;;;;;;;;;;;;;;;;;;;;;AAEH,6CAA+B;AAE/B,6CAA6D;AAE7D,iDAA4C;AAmD5C;;;;;;;;;;;;;;;;;;;;;GAqBG;AACI,KAAK,UAAU,WAAW,CAC/B,SAA6B,EAC7B,OAA2B;IAE3B,MAAM,EACJ,IAAI,EACJ,IAAI,GAAG,EAAE,EACT,UAAU,GAAG,CAAC,EACd,QAAQ,EACR,cAAc,GAAG,KAAK,GACvB,GAAG,OAAO,CAAC;IAEZ,2DAA2D;IAC3D,8DAA8D;IAC9D,MAAM,YAAY,GAAG,OAAO,CAAC,qBAAqB,CAAC,CAAC;IAEpD,MAAM,SAAS,GAAa,EAAE,CAAC;IAC/B,IAAI,gBAAgB,GAAG,CAAC,CAAC;IAEzB,mDAAmD;IACnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,CAAC,EAAE,EAAE;QACnC,MAAM,oBAAoB,CACxB,YAAY,EACZ,SAAS,EACT,GAAG,IAAI,WAAW,CAAC,EAAE,EACrB,QAAQ,EACR,cAAc,CACf,CAAC;KACH;IAED,0BAA0B;IAC1B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;QAC7B,MAAM,MAAM,GAAG,MAAM,oBAAoB,CACvC,YAAY,EACZ,SAAS,EACT,GAAG,IAAI,QAAQ,CAAC,EAAE,EAClB,QAAQ,EACR,cAAc,CACf,CAAC;QACF,SAAS,CAAC,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAC;QAChC,gBAAgB,IAAI,MAAM,CAAC,WAAW,CAAC;KACxC;IAED,OAAO;QACL,IAAI;QACJ,YAAY,EAAE,IAAA,iBAAI,EAAC,SAAS,CAAC;QAC7B,cAAc,EAAE,IAAA,mBAAM,EAAC,SAAS,CAAC;QACjC,MAAM,EAAE,IAAA,8BAAiB,EAAC,SAAS,CAAC;QACpC,WAAW,EAAE,IAAI,CAAC,KAAK,CAAC,gBAAgB,GAAG,IAAI,CAAC;QAChD,IAAI;QACJ,SAAS,EAAE,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE;KACpC,CAAC;AACJ,CAAC;AApDD,kCAoDC;AAED;;GAEG;AACH,KAAK,UAAU,oBAAoB,CACjC,YAAkD,EAClD,SAA6B,EAC7B,UAAkB,EAClB,QAAoD,EACpD,iBAA0B,KAAK;IAE/B,MAAM,OAAO,GAAqB,EAAE,CAAC;IAErC,MAAM,QAAQ,GAAG,CAAC,MAAsB,EAAE,EAAE;QAC1C,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IACvB,CAAC,CAAC;IAEF,MAAM,gBAAgB,GAAG,KAAK,CAAC,aAAa,CAAC,2BAAY,EAAE;QACzD,EAAE,EAAE,UAAU;QACd,QAAQ;QACR,QAAQ,EAAE,SAAS;KACpB,CAAC,CAAC;IAEH,IAAI,QAAgD,CAAC;IAErD,IAAI,cAAc,EAAE;QAClB,6BAA6B;QAC7B,QAAQ,GAAG,YAAY,CAAC,MAAM,CAAC,gBAAgB,CAAC,CAAC;QAEjD,iCAAiC;QACjC,OAAO,CAAC,MAAM,GAAG,CAAC,CAAC;QAEnB,kBAAkB;QAClB,MAAM,YAAY,GAAG,WAAW,CAAC,GAAG,EAAE,CAAC;QACvC,QAAQ,CAAC,OAAO,EAAE,CAAC;QACnB,MAAM,eAAe,GAAG,WAAW,CAAC,GAAG,EAAE,GAAG,YAAY,CAAC;QAEzD,OAAO;YACL,QAAQ,EAAE,eAAe;YACzB,WAAW,EAAE,CAAC;SACf,CAAC;KACH;IAED,gBAAgB;IAChB,MAAM,UAAU,GAAG,WAAW,CAAC,GAAG,EAAE,CAAC;IACrC,QAAQ,GAAG,YAAY,CAAC,MAAM,CAAC,gBAAgB,CAAC,CAAC;IACjD,MAAM,aAAa,GAAG,WAAW,CAAC,GAAG,EAAE,GAAG,UAAU,CAAC;IAErD,sCAAsC;IACtC,IAAI,QAAQ,EAAE;QACZ,MAAM,OAAO,GAAkB;YAC7B,QAAQ,EAAE,CAAC,OAA2B,EAAE,EAAE;gBACxC,MAAM,aAAa,GAAG,KAAK,CAAC,aAAa,CAAC,2BAAY,EAAE;oBACtD,EAAE,EAAE,UAAU;oBACd,QAAQ;oBACR,QAAQ,EAAE,OAAO;iBAClB,CAAC,CAAC;gBACH,QAAQ,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;YACjC,CAAC;YACD,OAAO,EAAE,GAAG,EAAE;gBACZ,QAAQ,CAAC,OAAO,EAAE,CAAC;YACrB,CAAC;SACF,CAAC;QACF,MAAM,QAAQ,CAAC,OAAO,CAAC,CAAC;KACzB;IAED,WAAW;IACX,IAAI,QAAQ,EAAE;QACZ,IAAI;YACF,QAAQ,CAAC,OAAO,EAAE,CAAC;SACpB;QAAC,WAAM;YACN,gCAAgC;SACjC;KACF;IAED,sEAAsE;IACtE,MAAM,mBAAmB,GAAG,OAAO,CAAC,MAAM,CACxC,CAAC,GAAG,EAAE,CAAC,EAAE,EAAE,CAAC,GAAG,GAAG,CAAC,CAAC,cAAc,EAClC,CAAC,CACF,CAAC;IAEF,OAAO;QACL,QAAQ,EAAE,mBAAmB,GAAG,CAAC,CAAC,CAAC,CAAC,mBAAmB,CAAC,CAAC,CAAC,aAAa;QACvE,WAAW,EAAE,OAAO,CAAC,MAAM;KAC5B,CAAC;AACJ,CAAC","sourcesContent":["/**\r\n * Copyright (c) Microsoft Corporation.\r\n * Licensed under the MIT License.\r\n *\r\n * @format\r\n */\r\n\r\nimport * as React from 'react';\r\nimport type {PerfMetrics} from '../interfaces/PerfMetrics';\r\nimport {mean, median, standardDeviation} from './statistics';\r\nimport type {ProfilerResult} from './PerfProfiler';\r\nimport {PerfProfiler} from './PerfProfiler';\r\n\r\n/**\r\n * Options for the `measurePerf` function.\r\n */\r\nexport interface MeasurePerfOptions {\r\n  /** Scenario name for identification in snapshots and reports */\r\n  name: string;\r\n\r\n  /** Number of measurement runs. Default: 10 */\r\n  runs?: number;\r\n\r\n  /** Warmup runs that are not recorded. Default: 1 */\r\n  warmupRuns?: number;\r\n\r\n  /**\r\n   * Optional async callback executed after each render.\r\n   * Use this to simulate user interactions (scroll, type, press).\r\n   *\r\n   * @param helpers - Render helpers providing access to the rendered tree.\r\n   */\r\n  scenario?: (helpers: RenderHelpers) => Promise<void>;\r\n\r\n  /** Whether to measure unmount time instead of mount time. Default: false */\r\n  measureUnmount?: boolean;\r\n}\r\n\r\n/**\r\n * Helpers passed to scenario callbacks during measurement.\r\n */\r\nexport interface RenderHelpers {\r\n  /**\r\n   * Trigger a re-render by updating the component.\r\n   * Implementations should call `rerender()` from the test renderer.\r\n   */\r\n  rerender: (element: React.ReactElement) => void;\r\n\r\n  /**\r\n   * Unmount the rendered component tree.\r\n   */\r\n  unmount: () => void;\r\n}\r\n\r\n/**\r\n * Result from a single measurement iteration.\r\n */\r\ninterface SingleRunResult {\r\n  duration: number;\r\n  renderCount: number;\r\n}\r\n\r\n/**\r\n * Core measurement function.\r\n *\r\n * Renders a component multiple times wrapped in React.Profiler,\r\n * collects timing data, and returns aggregated metrics.\r\n *\r\n * This function is the foundation of all perf tests. Both the base class\r\n * and individual scenarios use this to collect measurements.\r\n *\r\n * @param component - The React element to measure.\r\n * @param options - Configuration for the measurement run.\r\n * @returns Aggregated performance metrics.\r\n *\r\n * @example\r\n * ```typescript\r\n * const metrics = await measurePerf(\r\n *   <View testID=\"perf-view\" style={{ flex: 1 }} />,\r\n *   { name: 'View mount', runs: 10 }\r\n * );\r\n * expect(metrics).toMatchPerfSnapshot();\r\n * ```\r\n */\r\nexport async function measurePerf(\r\n  component: React.ReactElement,\r\n  options: MeasurePerfOptions,\r\n): Promise<PerfMetrics> {\r\n  const {\r\n    name,\r\n    runs = 10,\r\n    warmupRuns = 1,\r\n    scenario,\r\n    measureUnmount = false,\r\n  } = options;\r\n\r\n  // Lazy-require react-test-renderer to keep it as a peerDep\r\n  // eslint-disable-next-line @typescript-eslint/no-var-requires\r\n  const TestRenderer = require('react-test-renderer');\r\n\r\n  const durations: number[] = [];\r\n  let totalRenderCount = 0;\r\n\r\n  // Warmup runs â€” not recorded, stabilize JIT/caches\r\n  for (let i = 0; i < warmupRuns; i++) {\r\n    await runSingleMeasurement(\r\n      TestRenderer,\r\n      component,\r\n      `${name}-warmup-${i}`,\r\n      scenario,\r\n      measureUnmount,\r\n    );\r\n  }\r\n\r\n  // Actual measurement runs\r\n  for (let i = 0; i < runs; i++) {\r\n    const result = await runSingleMeasurement(\r\n      TestRenderer,\r\n      component,\r\n      `${name}-run-${i}`,\r\n      scenario,\r\n      measureUnmount,\r\n    );\r\n    durations.push(result.duration);\r\n    totalRenderCount += result.renderCount;\r\n  }\r\n\r\n  return {\r\n    name,\r\n    meanDuration: mean(durations),\r\n    medianDuration: median(durations),\r\n    stdDev: standardDeviation(durations),\r\n    renderCount: Math.round(totalRenderCount / runs),\r\n    runs,\r\n    timestamp: new Date().toISOString(),\r\n  };\r\n}\r\n\r\n/**\r\n * Execute a single measurement iteration.\r\n */\r\nasync function runSingleMeasurement(\r\n  TestRenderer: typeof import('react-test-renderer'),\r\n  component: React.ReactElement,\r\n  profilerId: string,\r\n  scenario?: (helpers: RenderHelpers) => Promise<void>,\r\n  measureUnmount: boolean = false,\r\n): Promise<SingleRunResult> {\r\n  const results: ProfilerResult[] = [];\r\n\r\n  const onResult = (result: ProfilerResult) => {\r\n    results.push(result);\r\n  };\r\n\r\n  const wrappedComponent = React.createElement(PerfProfiler, {\r\n    id: profilerId,\r\n    onResult,\r\n    children: component,\r\n  });\r\n\r\n  let renderer: ReturnType<typeof TestRenderer.create>;\r\n\r\n  if (measureUnmount) {\r\n    // Mount first (not measured)\r\n    renderer = TestRenderer.create(wrappedComponent);\r\n\r\n    // Clear results from mount phase\r\n    results.length = 0;\r\n\r\n    // Measure unmount\r\n    const unmountStart = performance.now();\r\n    renderer.unmount();\r\n    const unmountDuration = performance.now() - unmountStart;\r\n\r\n    return {\r\n      duration: unmountDuration,\r\n      renderCount: 0,\r\n    };\r\n  }\r\n\r\n  // Measure mount\r\n  const mountStart = performance.now();\r\n  renderer = TestRenderer.create(wrappedComponent);\r\n  const mountDuration = performance.now() - mountStart;\r\n\r\n  // Execute custom scenario if provided\r\n  if (scenario) {\r\n    const helpers: RenderHelpers = {\r\n      rerender: (element: React.ReactElement) => {\r\n        const wrappedUpdate = React.createElement(PerfProfiler, {\r\n          id: profilerId,\r\n          onResult,\r\n          children: element,\r\n        });\r\n        renderer.update(wrappedUpdate);\r\n      },\r\n      unmount: () => {\r\n        renderer.unmount();\r\n      },\r\n    };\r\n    await scenario(helpers);\r\n  }\r\n\r\n  // Clean up\r\n  if (renderer) {\r\n    try {\r\n      renderer.unmount();\r\n    } catch {\r\n      // Already unmounted by scenario\r\n    }\r\n  }\r\n\r\n  // Use Profiler actualDuration if available, fallback to manual timing\r\n  const totalActualDuration = results.reduce(\r\n    (sum, r) => sum + r.actualDuration,\r\n    0,\r\n  );\r\n\r\n  return {\r\n    duration: totalActualDuration > 0 ? totalActualDuration : mountDuration,\r\n    renderCount: results.length,\r\n  };\r\n}\r\n"]}